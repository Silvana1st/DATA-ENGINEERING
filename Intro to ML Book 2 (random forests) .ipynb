{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./intro_images/HDSbanner.jpg\" width=\"100%\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:right;\">\n",
    "    <tr>\n",
    "        <td>                      \n",
    "            <div style=\"text-align: right\"><a href=\"https://alandavies.netlify.com\" target=\"_blank\">Dr Alan Davies</a></div>\n",
    "            <div style=\"text-align: right\">Senior Lecturer health data science</div>\n",
    "            <div style=\"text-align: right\">University of Manchester</div>\n",
    "         </td>\n",
    "         <td>\n",
    "             <img src=\"https://github.com/i3hsInnovation/resources/blob/efa61022d0b8893200dad308f6590e694291f8c7/images/alan.PNG?raw=true\" width=\"30%\" />\n",
    "         </td>\n",
    "     </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Random Forests \n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About this Notebook\n",
    "This notebook introduces a Machine Learning algorithm called Random Forests which is built in turn on Decision Trees. We will apply these algorithms to some real world data introduced in the notebook Working with Data.  Random Forests use the ‘wisdom of crowds’ to make their prediction, so for example, when you gather lots of the opinions in a crowd many individual ones will often be wrong but collectively the correct viewpoint usually becomes apparent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Learning Objectives:</b> \n",
    "<br/> At the end of this notebook you will be able to:\n",
    "    \n",
    "- Investigate key features of Random Forest machine learning algorithms \n",
    "\n",
    "- Explore some essential Machine Learning Python libraries to implement Machine Learning algorithms\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "<b>Table of contents</b><br/>\n",
    "\n",
    "1.0 [Decision Trees](#decisiontrees)\n",
    "\n",
    "2.0 [Random Forests](#randomforests)\n",
    "\n",
    "3.0 [Classification](#classification)\n",
    "\n",
    "4.0 [Interpreting the Results](#Interpretingresults)\n",
    "\n",
    "5.0 [Feature Importance](#Featureimportance)\n",
    "\n",
    "6.0 [Your Turn](#yourturn)\n",
    "\n",
    "7.0 [Further Reading](#furtherreading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "\n",
    "<a id=\"decisiontrees\"></a>\n",
    "\n",
    "## 1.0 Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>Decision tree</code> algorithms were first introduced decades ago. Modern variants use these trees as the basis for more powerful techniques such as <code>Random Forests</code>, which are some of today's most powerful methods. It can be difficult to understand how some Machine Learning algorithms arrive at their conclusions. This has led to many of these algorithms being described as <a href=\"https://towardsdatascience.com/the-black-box-metaphor-in-machine-learning-4e57a3a1d2b0\" target=\"_blank\" >Black boxes</a>. One of the advantages of using decision trees and methods based on them is that they are much easier to explain and understand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A statistician called <strong>Leo Breiman</strong> from the University of California coined the term <code>CART</code>, which stands for <code>classification and regression trees</code>.  These  algorithms  are  capable  of  carrying out both <code>regression</code> and <code>classification</code> tasks. Leo worked at the intersection between Computer Science and Statistics and promoted real world problem solving over theoretical concerns. Sadly he did not live to see how wide spread the use of this algorithms would become. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<strong>Note:</strong>\n",
    "If you are interested, there is a paper <a href=\"https://projecteuclid.org/euclid.ss/1009213726\" target=\"_blank\">here</a> where Leo contrasts the two cultures of data modeling (stochastic data models and algorithmic models).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to note is that unlike a conventional tree that grows upwards, these trees tend to be represented from the top down or sideways. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ml_files/tree1.png\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The anatomy of a tree can be seen below. This details the names of the main nodes and sections of a typical tree structure. The tree represents the criteria for making choices and shows how logical choices can be made based on following these individual criteria until we reach a final conclusion (decision)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<strong>Note:</strong>\n",
    "<ul>\n",
    "    <li><strong>Classification:</strong> Predicting which <i>class</i> (discrete label) a data point belongs to.</li>\n",
    "    <li><strong>Regression:</strong> Predicting a <i>quantity</i> (continuous value).</li>\n",
    "</ul>\n",
    "<br />\n",
    "For more information, see <a href=\"https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/\" target=\"_blank\">Difference Between Classification and Regression in Machine Learning</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ml_files/nodes.png\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first example above shows a decision tree that could be used to determine to lend money to someone (or not) based on their income and rental expenses.The first node (Income < 25K) is termed the <code>root node</code> representing the entire sample that is further subdivided. Sub-nodes that are further divided are called <code>decision nodes</code>. Nodes with proceeding nodes are also called <code>parent nodes</code> with subsequent nodes referred to as <code>child nodes</code>. If a node has no child nodes it is termed a <code>leaf</code> or <code>terminal</code> node. And finally a sub-section of a tree is called a <code>branch</code> or <code>sub-tree</code>. Below is what an actual tree generated with a Python Machine Learning library looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ml_files/tree.png\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The splitting of data is performed via <code>recursive greedy binary splitting</code>. This means a repeated action is used to split data into 2 parts. The greedy element refers to the way the best decision is made at the current step, rather than considering future splits that might lead to an overall better tree. This is achieved by comparing every feature and value until the best split can be achieved. The way this is done is dependent on if you are using the algorithm for regression or classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<strong>Note:</strong>\n",
    "    For <strong>regression</strong> the <code>mean square error (MSE)</code> or <code>sum of squared errors (SSE)</code> are typically used to find the optimal split. <br><br>\n",
    "    $$ MSE = \\frac{1}{n} \\displaystyle\\sum_{i-1}^{n}(Y_i - \\hat{Y}_i)^2 $$\n",
    "    <br>In the case of <strong>classification</strong> the <code>class error rate</code>, <code>cross entropy</code> or most commonly the <code>Gini index/impurity</code> is used. If the index is 0 then all the cases belong to a specific target category:\n",
    "    $$ Gini_{i} = \\displaystyle\\sum_{k=1}^{K} \\hat{p}_{mk}(1 - \\hat{p}_{mk}) $$\n",
    "<br><br>\n",
    "    Although helpful, it is not necessary to understand the underlying mathematics in order to use the Machine Learning libraries in Python.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees are useful when data is <code>linearly inseparable</code>. Consider the image below. The image on the left shows that the data can be easily separated with a line to divide the stars and triangles, which in this example represent 2 different classes of something (e.g. cats and dogs). This ability to separate data with a line means it is <code>linearly separable</code>. You can see however that this won't work with the image on the right. We can't separate our data with a single line. This means that the data on the right is <code>linearly inseparable</code>. Decision trees can deal with this type of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ml_files/sep.png\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "<a id=\"randomforests\"></a>\n",
    "\n",
    "## 2.0 Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the decision tree is easy to explain and interpret, it lacks predictive power and can create complicated trees that fit the data well but do not generalize well to new data (called <code>overfitting</code>). Small variations in the data (<code>variance</code>) can lead to very different trees being created. One way to improve this is to use multiple trees. This is essentially what a Random Forest is. This is known as an <code>ensemble</code> method, where many weak learners can combine to create a more powerful one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>sklearn</code> Python library has some datasets that are built in. We will use one of these datasets to apply a Random Forest in Python for the purposes of classifying data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import the Breast cancer dataset from the <a href=\"https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\">UCI ML Breast Cancer Wisconsin (Diagnostic)</a> and the <code>pandas</code> module as it it useful for data science and supports objects like <code>data frames</code> that can display our data in tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 1:</b>\n",
    "<br> \n",
    "Have a look at the link to the data presented in the link above. <br>\n",
    "    1. What information is presented about the data?<br>\n",
    "    2. What information does the dataset capture?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we load the dataset into a variable called <code>cancer</code>. The other lines of code make sure that we have the correct column names. Finally on the last line, we store the data in a dataframe object called <code>df</code> (short for data frame) to make it easier to manipulate the data in a tabular form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "data = np.c_[cancer.data, cancer.target]\n",
    "columns = np.append(cancer.feature_names, [\"target\"])\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can view the <code>head</code> of the data to see what the data looks like. In this case the first 25 records. Note the <code>target</code> column at the far right of the data table output below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<strong>Note:</strong>\n",
    "    A value of <code>0</code> means <strong>benign</strong> (not cancer), whereas a value of <code>1</code> means it is <strong>malignant</strong> (cancer). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "<a id=\"classification\"></a>\n",
    "\n",
    "## 3.0 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to train a classifier so that when we provide it with new data (say from new patients), it can determine if this new data should be classified as being either cancer or no-cancer. To do this we will split our data into a <code>training</code> and <code>test</code> set. We can use the training data to train our model and then see how well the model performs against the previously unseen test data. Remember that a model is only an approximation (abstraction) of a real world situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ml_files/model.png\" width=\"60%\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step involves separating the <code>features</code> (column names) from the <code>label</code> (in this case <strong>target</strong>). We can do this to all the data before we do any splitting of the data. You will recall from the previous notebook that to do this we can use the integer location indexing from pandas to get all the columns apart from the last one (0 to -1). We will store the features in a variable called <code>X</code> and the labels in a variable called <code>y</code> as is conventional.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import a function called <code>train_test_split</code> that has been specially designed to help us do this data splitting as it is a common step in Machine Learning. We will have training and testing sets for <code>X</code> and for <code>y</code>. Here we specify the size of the test set as <strong>25%</strong> of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a training and test split for features <code>X</code> (<code>X_train</code>, <code>X_test</code>) and for the labels <code>y</code> (<code>y_train</code>, <code>y_test</code>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<strong>Note:</strong>\n",
    "    The <code>train_test_split</code> function converts the data into a <code>numpy.ndarray</code> (a multidimensional, homogeneous array of fixed-size items). This format works well with the various Machine Learning algorithms, but this means that we can no longer use functions like <code>head()</code> to view the data as it is now not a dataframe any more. We could view such data with Python's <code>print()</code> function (e.g. <code>print(y_train)</code>).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to import the <code>classifier</code> that we want to use. In this case, this is the classifier for Random Forests which is called <code>RandomForestClassifier</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the classifier. In this case we will call it <code>rf</code> for Random Forest. The <code>n_estimators</code> parameter is the <strong>number of trees</strong> that you will use in your 'forest'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<strong>Note:</strong> We can add other parameters to our classifier. For example we can change the cost function used. So to use the Gini index described previously, we could write <code>RandomForestClassifier(n_estimators=5000, criterion=\"gini\")</code> or change <code>gini</code> to <code>entropy</code>. The Gini index is used by default so we don't specify this explicitly. <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" target=\"_blank\">Here</a> are more details of the possible parameters you can use.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To <code>train</code> our data we use the <code>fit()</code> function, passing in the training features and training labels. More specifically the fit function adjusts weights in accordance with data values to achieve better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 2:</b>\n",
    "<br> \n",
    "Write the line of code above again in the cell below. This time do not add the colon (;) at the end of the line. This will output all of the functions default parameters.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can use the <code>predict()</code> function to predict the label for some new hitherto unseen data. For this we use our test data (<code>X_test</code>). The predicted values are then stored in a variable called <code>y_pred</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "<a id=\"Interpretingresults\"></a>\n",
    "\n",
    "\n",
    "## 4. Interpreting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a model has been produced, we then need to evaluate how effective it is. There are several approaches we can take which can include looking at a range of metrics and using visualisations. The <code>sklearn</code> library has some useful functions for producing metrics for evaluating Machine Learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common is the <code>accuracy</code>. This is used as a measure of performance and refers to the ratio of correctly predicted samples out of all available samples. This can be defined as follows:\n",
    "$$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<strong>Note:</strong>\n",
    "    <ul>\n",
    "        <li>TP = True Positive</li>\n",
    "        <li>TN = True Negative</li>\n",
    "        <li>FP = False Positive</li>\n",
    "        <li>FN = False Negative</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this in Python we can use the <code>accuracy_score()</code> function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can round this up so we don't include so many numbers. For example to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",round(metrics.accuracy_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 3:</b>\n",
    "<br> \n",
    "1. Convert the accuracy to a percentage.<br>\n",
    "    2. Output the result with the <code>print()</code> function to 2 decimal places.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\",round(acc*100, 2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to visualise how well the model performs in terms of prediction is to view this in the form of a <code>confusion matrix</code>. This is a table that shows the predicted against the actual class. We can do this with the <code>confusion_matrix()</code> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides the necessary data but it is difficult to interpret what it is showing us. We can use a plot to display this in a more intuitive way. First we will store the data from the confusion matrix in a variable called <code>conf_mat</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Actual vs. predicted confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be clearer now that we can see the true and false positives. We can also extract these values from the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = conf_mat[0][0]\n",
    "FP = conf_mat[0][1]\n",
    "FN = conf_mat[1][0]\n",
    "TP = conf_mat[1][1]\n",
    "\n",
    "print(\"True positive:\",TP)\n",
    "print(\"False positive:\", FP)\n",
    "print(\"False negative:\", FN)\n",
    "print(\"True negative:\", TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>Note:</strong> Another way of achieving this is to use the <code>ravel()</code> function. e.g. <code>tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 4:</b>\n",
    "<br> \n",
    "1. Given the variables above (TN, FP, FN and TP), manually compute and display the accuracy. Remember:<br>\n",
    "$$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} $$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful metric is <code>Precision</code>. This shows us the percentage of positive classifications that were correct, or in other words, how precise were we. Precision is also sometimes called <code>positive predictive value</code>.<br>\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also called <code>sensitivity</code> or <code>true positive rate</code>, shows the proportion of correct identifications over the total amount of relevant instances, or in other words, the proportion of actual positives identified correctly. These two metrics (precision and recall) are often juxtaposed, and the attempt to improve one often negatively impacts on the other.<br>\n",
    "$$\\text{Recall} = \\frac{TP}{TP + FN} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the harmonic mean (an average) of the precision and recall.<br>\n",
    "$$F_1 = 2 \\times \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 5:</b>\n",
    "<br> \n",
    "1. Manually calculate the F1 score. <br>\n",
    "    <strong>Hint:</strong> you will first need to calculate the precision and recall.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "prec = TP / (TP + FP)\n",
    "rec = TP / (TP + FN)\n",
    "F1 = 2 * (prec * rec) / (prec + rec)\n",
    "print(\"F1 score:\",round(F1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be hard work. Luckily there is a function that can be used to calculate these common metrics for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>classification_report()</code> function can be used to output a table of useful metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>Note:</strong> The Support refers to the number of times a class occurs in the ground truth (the correct target values).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract the individual values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = score(y_test, y_pred, average='macro')\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F-score:', fscore)\n",
    "print('Support:', support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Receiver operating characteristics (ROC) curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of visualising the trade off between the true and false positive rates is to view this with a ROC curve. The true positive rate (TPR) can be plotted against the false positive rate (FPR) using different threshold values. We can also compare multiple models on the same plot to help choose the best one. Good performance is indicated by a curve that hugs the left vertical and top horizontal position of the graph (i.e. has the most area under the curve) shown in green on the image below. The plot shows the trade-off between both the sensitivity and specificity of a model. The closer the curve to the 45 degree dashed line, the worse the model's performance. The area under the curve (AUC) is often used to quantify and compare different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ml_files/roc.png\" width=\"40%\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Source: </strong>Tharwat, (2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>Note:</strong> The TPR is also called <code>sensitivity</code> or <code>recall</code> as described above. <br>\n",
    "  $$\\text{TPR} = \\frac{TP}{TP + FN} $$\n",
    "    The FPR is determined by:<br>\n",
    "    $$\\text{FPR} = \\frac{FP}{FP + TN} $$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this in Python we can use the <code>roc_curve</code> function from the <code>metrics</code> library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "<a id=\"Featureimportance\"></a>\n",
    "\n",
    "\n",
    "## 5. Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also order the features in terms of their importance. This refers to their importance in terms of explaining the target variable, so in our case cancer or no-cancer. This works by calculating how much contributes each feature makes to decreasing the weighted impurity of the cost function we are using. To do this we use the <code>feature_importances_</code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(df.columns.values)\n",
    "col_names = col_names[:-1]\n",
    "feature_imp = pd.Series(rf.feature_importances_,index=col_names).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import the required libraries for visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can output the features in terms of their importance in the form of a bar plot. We see here that the feature at the top is the most 'important' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "plt.xlabel('Feature importance score')\n",
    "plt.ylabel('Features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "<a id=\"yourturn\"></a>\n",
    "\n",
    "\n",
    "# 6. Your Turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and apply what we have learned about Random Forests to a new dataset. This is the <code>pima-indians-diabetes</code> <a href=\"https://www.kaggle.com/kumargh/pimaindiansdiabetescsv/data\">dataset</a> from Kaggle that you saw previously. Click on the dataset link above and read the description of the data fields (columns) in the section called <code>About this file</code> so that you understand what sort of data is contained in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the file and then display the first 10 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./ml_files/pima-indians-diabetes.csv'\n",
    "data = pd.read_csv(path)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 6:</b>\n",
    "<br> \n",
    "    Split the data into features <code>X</code> and labels <code>y</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:, 0:-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 7:</b>\n",
    "<br> \n",
    "    Now split the data into <code>training</code> and <code>test</code> data for both features and labels.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 8:</b>\n",
    "<br> \n",
    "    Create a <code>RandomForestClassifier</code> classifier with <code>5000</code> trees.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=5000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 9:</b>\n",
    "<br> \n",
    "    Train the classifier with the <code>fit()</code> function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 10:</b>\n",
    "<br> \n",
    "    Make some predictions with your test data using the <code>predict()</code> function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 11:</b>\n",
    "<br> \n",
    "1. Using the <code>classification_report()</code>, generate a report.<br>\n",
    "2. Analyse the performance of your classifier. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 12:</b>\n",
    "<br> \n",
    "1. Create a plot for the importance of features.<br>\n",
    "2. Does it show what you expected?, why?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "col_names = list(data.columns.values)\n",
    "col_names = col_names[:-1]\n",
    "feature_imp = pd.Series(rf.feature_importances_,index=col_names).sort_values(ascending=False)\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "plt.xlabel('Feature importance score')\n",
    "plt.ylabel('Features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 13:</b>\n",
    "<br> \n",
    "1. Finally plot a confusion matrix and analyse the results. <br>\n",
    "2. Did this perform as well on this dataset as it did on the cancer dataset?<br>\n",
    "3. Why could this be the case?<br>\n",
    "4. Can you modify any of your parameters (e.g. number of trees, percentage of data used for training) to improve performance?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Actual vs. predicted confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "<a id=\"furtherreading\"></a>\n",
    "\n",
    "\n",
    "## 7. Further Reading\n",
    "\n",
    "Tharwat, A. (2018) <u><i>Classification assessment methods</u></i>. Applied Computing and Informatics, August 2018: https://doi.org/10.1016/j.aci.2018.08.003\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "#### Notebook details\n",
    "<br>\n",
    "<i>Notebook created by <strong>Dr. Alan Davies</strong> with, <strong>Frances Hooley</strong> and <strong>Dr. Jon Parkinson</strong>\n",
    "\n",
    "Publish date: April 2020<br>\n",
    "Review date: September 2021</i>\n",
    "\n",
    "<strong>Note:</strong> This notebook features extracts from: <br>\n",
    "<a href=\"https://link.springer.com/book/10.1007%2F978-3-030-47499-7#toc\" target=\"_blank\">Davies, A., Mueller, J. (2020) Developing Medical Apps and mHealth Interventions: A Guide for Researchers, Physicians and Informaticians. Springer: Switzerland</a>\n",
    "\n",
    "Please give some feedback using the button below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"typeform-share button\" href=\"https://hub11.typeform.com/to/qRicvM22\" data-mode=\"popup\" style=\"display:inline-block;text-decoration:none;background-color:#3A7685;color:white;cursor:pointer;font-family:Helvetica,Arial,sans-serif;font-size:18px;line-height:45px;text-align:center;margin:0;height:45px;padding:0px 30px;border-radius:22px;max-width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;font-weight:bold;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;\" target=\"_blank\">Rate this notebook </a> <script> (function() { var qs,js,q,s,d=document, gi=d.getElementById, ce=d.createElement, gt=d.getElementsByTagName, id=\"typef_orm_share\", b=\"https://embed.typeform.com/\"; if(!gi.call(d,id)){ js=ce.call(d,\"script\"); js.id=id; js.src=b+\"embed.js\"; q=gt.call(d,\"script\")[0]; q.parentNode.insertBefore(js,q) } })() </script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
